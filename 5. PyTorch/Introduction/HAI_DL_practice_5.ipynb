{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **5. Build the Neural Network**"
      ],
      "metadata": {
        "id": "hdmk2K07Zcx0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neural network는 데이터에 대해 여러 연산을 수행하는 layer로 구성됨\n",
        "\n",
        "torch.nn 은 신경망을 직접 구축하는데 필요한 모든 기본 구성 요소들을 제공\n",
        "\n",
        "신경망 또한 하나의 모듈이고 그 안에 여러 개의 모듈(레이어)를 포함하는 구조\n",
        "\n",
        "이러한 중첩 구조(nested structure) 덕분에 복잡한 신경망 아키텍쳐도 효율적으로 구성하고 관리할 수 있음"
      ],
      "metadata": {
        "id": "xunaO31_auFY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jMScR1iuZaI-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_H-HeFvacUO",
        "outputId": "f010698c-211d-4b14-a07d-9ced13694ca7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define the Class\n"
      ],
      "metadata": {
        "id": "1ap_xYOibMBR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pytorch 에서 모든 신경망은 nn.Module을 상속해서 만듬\n",
        "class NeuralNetwork(nn.Module):\n",
        "  # 네트워크 구조를 정의\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.linear_relu_stack = nn.Sequential(\n",
        "        nn.Linear(28*28, 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512, 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512, 10),\n",
        "    )\n",
        "\n",
        "  # 입력 데이터의 흐름을 정의\n",
        "  # x를 flatten하고 쌓아둔 layer를 통과시킴\n",
        "  # 그리고 logits(소프트맥스 전에 출력되는 벡터)을 반환\n",
        "  def forward(self, x):\n",
        "    x = self.flatten(x)\n",
        "    logits = self.linear_relu_stack(x)\n",
        "    return logits\n",
        "\n",
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGSvFK7AbHAe",
        "outputId": "0fb9f48c-abf3-4ef1-e32d-e5d9f7e465d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.rand(1, 28, 28, device=device) # 입력 이미지 하나 생성 (랜덤값으로 만드니까)\n",
        "logits = model(X) # 모델에 입력을 넣어서 logits 계산\n",
        "pred_probab = nn.Softmax(dim=1)(logits) # softmax로 각 클래스별 확률 계산\n",
        "y_pred = pred_probab.argmax(1) # 가장 높은 확률을 가진 클래스를 예측 결과로\n",
        "print(f\"predicated class: {y_pred}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DsVlQnWAbzoQ",
        "outputId": "64512b31-2ca7-4c31-fbfd-43905adf7d26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicated class: tensor([1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Layers"
      ],
      "metadata": {
        "id": "A8CTI9p2c54N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_image = torch.rand(3, 28, 28)\n",
        "print(input_image.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHnnUsW0cvQy",
        "outputId": "1bae35a7-2271-4bde-ea53-27bf2670f7e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 28, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# nn.Flatten"
      ],
      "metadata": {
        "id": "JjxfzEm_di0L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "flatten을 통해 이미지 3장을 3,784로 바꿈"
      ],
      "metadata": {
        "id": "b3jaEdCVfXkG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "flatten = nn.Flatten()\n",
        "flat_image = flatten(input_image)\n",
        "print(flat_image.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6QzwtthdIhk",
        "outputId": "83dd289e-50f6-424c-961c-25302176923d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 784])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# nn.Linear"
      ],
      "metadata": {
        "id": "yUkNZ55Ad1IK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "입력 784 -> 20 으로 선형 변환 시킴"
      ],
      "metadata": {
        "id": "Y7W9YcJgff44"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layer1 = nn.Linear(in_features = 28*28, out_features = 20)\n",
        "hidden1 = layer1(flat_image)\n",
        "print(hidden1.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SamdwISndqz9",
        "outputId": "5d604c7a-1eef-4d0d-a6e6-62afd56cdc9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 20])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# nn.ReLU"
      ],
      "metadata": {
        "id": "eDBOVmXMeEjb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ReLU 이후 값을 확인해 보면 음수값은 0으로 되고 양수값은 그대로 유지되는 것을 확인할 수 있음"
      ],
      "metadata": {
        "id": "V0WN4ZdlflIm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Before ReLU: {hidden1}\\n\\n\")\n",
        "hidden1 = nn.ReLU()(hidden1)\n",
        "print(f\"After ReLU: {hidden1}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gfOXjs60eAx3",
        "outputId": "103965a4-0508-4231-a75c-40e7d9ca9df5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before ReLU: tensor([[-0.5496, -0.5485, -0.3551,  0.0160, -0.5700,  0.2855, -0.6189,  0.7105,\n",
            "          0.0067,  0.1517, -0.0197,  0.1228,  0.0251,  0.8445, -0.0536, -0.0212,\n",
            "          0.2953,  0.7620,  0.0828, -0.2206],\n",
            "        [-0.4959, -0.2937, -0.1727, -0.1377, -0.5198,  0.2325, -0.0708,  0.5165,\n",
            "          0.0914,  0.1246,  0.0165,  0.1722,  0.0802,  0.3802,  0.2920,  0.1719,\n",
            "          0.3584,  0.3179,  0.4968, -0.5367],\n",
            "        [-0.2523, -0.0689, -0.1692,  0.0777, -0.2076,  0.3334, -0.0826,  1.0497,\n",
            "          0.1373,  0.4599, -0.2655,  0.2997,  0.0515,  0.3888, -0.0869, -0.1003,\n",
            "          0.2010,  0.2358,  0.1786, -0.1773]], grad_fn=<AddmmBackward0>)\n",
            "\n",
            "\n",
            "After ReLU: tensor([[0.0000, 0.0000, 0.0000, 0.0160, 0.0000, 0.2855, 0.0000, 0.7105, 0.0067,\n",
            "         0.1517, 0.0000, 0.1228, 0.0251, 0.8445, 0.0000, 0.0000, 0.2953, 0.7620,\n",
            "         0.0828, 0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2325, 0.0000, 0.5165, 0.0914,\n",
            "         0.1246, 0.0165, 0.1722, 0.0802, 0.3802, 0.2920, 0.1719, 0.3584, 0.3179,\n",
            "         0.4968, 0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0777, 0.0000, 0.3334, 0.0000, 1.0497, 0.1373,\n",
            "         0.4599, 0.0000, 0.2997, 0.0515, 0.3888, 0.0000, 0.0000, 0.2010, 0.2358,\n",
            "         0.1786, 0.0000]], grad_fn=<ReluBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# nn.Sequential\n"
      ],
      "metadata": {
        "id": "txfJ0E45ebfz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "레이어들의 컨테이너 역할을 하는것 시퀀셜이\n",
        "\n",
        "logits을 통해 예측까지 가능하게 끔 준비"
      ],
      "metadata": {
        "id": "SNG8BJcFfxWN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seq_modules = nn.Sequential(\n",
        "    flatten,\n",
        "    layer1,\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(20, 10)\n",
        ")\n",
        "input_image = torch.rand(3, 28, 28)\n",
        "logits = seq_modules(input_image)"
      ],
      "metadata": {
        "id": "mIfkedgcePwz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# nn.Softmax"
      ],
      "metadata": {
        "id": "zo88Ib4Jeoa9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "logts을 각 샘플마다 클래스의 확률 합이 1이 되게끔 softmax"
      ],
      "metadata": {
        "id": "uZPCaPTuf5lC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "softmax = nn.Softmax(dim=1)\n",
        "pred_probab = softmax(logits)"
      ],
      "metadata": {
        "id": "R7V5Y7EKenw3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Parameters"
      ],
      "metadata": {
        "id": "bDvVTr_7evN7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 단순하게 모델의 전체 구조를 출력\n",
        "print(f\"model structure: {model}\\n\\n\")\n",
        "\n",
        "# 각 파라미터에 대해 이름과 값의 쌍을 반환\n",
        "for name, param in model.named_parameters():\n",
        "  print(f\"layer: {name} | size: {param.size()} | values: {param[:2]}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRTXG8Wmet4J",
        "outputId": "3d578082-a94e-4fab-cf69-110eb1bd7d41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model structure: NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "\n",
            "\n",
            "layer: linear_relu_stack.0.weight | size: torch.Size([512, 784]) | values: tensor([[ 0.0087,  0.0077,  0.0164,  ..., -0.0094,  0.0229, -0.0122],\n",
            "        [-0.0309,  0.0323, -0.0281,  ..., -0.0068,  0.0198, -0.0291]],\n",
            "       grad_fn=<SliceBackward0>)\n",
            "\n",
            "layer: linear_relu_stack.0.bias | size: torch.Size([512]) | values: tensor([ 0.0320, -0.0032], grad_fn=<SliceBackward0>)\n",
            "\n",
            "layer: linear_relu_stack.2.weight | size: torch.Size([512, 512]) | values: tensor([[ 0.0194,  0.0292, -0.0172,  ..., -0.0213, -0.0214, -0.0324],\n",
            "        [-0.0250,  0.0344, -0.0167,  ...,  0.0345, -0.0296,  0.0117]],\n",
            "       grad_fn=<SliceBackward0>)\n",
            "\n",
            "layer: linear_relu_stack.2.bias | size: torch.Size([512]) | values: tensor([-0.0243, -0.0187], grad_fn=<SliceBackward0>)\n",
            "\n",
            "layer: linear_relu_stack.4.weight | size: torch.Size([10, 512]) | values: tensor([[ 0.0250,  0.0202, -0.0063,  ...,  0.0023,  0.0244, -0.0307],\n",
            "        [-0.0393, -0.0225,  0.0288,  ...,  0.0120,  0.0243, -0.0095]],\n",
            "       grad_fn=<SliceBackward0>)\n",
            "\n",
            "layer: linear_relu_stack.4.bias | size: torch.Size([10]) | values: tensor([0.0181, 0.0233], grad_fn=<SliceBackward0>)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PsOplwbKfKL2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}