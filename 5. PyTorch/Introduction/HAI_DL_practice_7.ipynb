{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **7. Optimizing Model Parameters**"
      ],
      "metadata": {
        "id": "5WT31Th9aLc_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델과 데이터를 준비했으니 이제는 모델을 학습, 검증, 테스트 하면서 파라미터를 최적화할 차례임\n",
        "\n",
        "모델 학습은 반복적인 과정임 각 반복에서 모델은 출력값을 추측하고, 그 추측이 얼마나 틀렸는지 loss로 계산\n",
        "\n",
        "그다음 오차에 대해 파라미터별로 얼마나 영향을 미쳤는지 gradient를 계산하고 이를 통해 파라미터를 업데이트하는 것\n",
        "\n"
      ],
      "metadata": {
        "id": "lxmyvLGSb48a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6vbBa19aJR2",
        "outputId": "08adde9f-ed2a-43ec-9783-83b6f0b534be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:02<00:00, 11.3MB/s]\n",
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 230kB/s]\n",
            "100%|██████████| 4.42M/4.42M [00:01<00:00, 4.23MB/s]\n",
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 11.2MB/s]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root = 'data',\n",
        "    train = True,\n",
        "    download = True,\n",
        "    transform = ToTensor()\n",
        ")\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root = 'data',\n",
        "    train = False,\n",
        "    download = True,\n",
        "    transform = ToTensor()\n",
        ")\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size = 64)\n",
        "test_dataloader = DataLoader(test_data, batch_size = 64)\n",
        "\n",
        "class NeuralNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.linear_relu_stack = nn.Sequential(\n",
        "        nn.Linear(28*28, 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512, 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512,10),\n",
        "        )\n",
        "  def forward(self, x):\n",
        "    x = self.flatten(x)\n",
        "    logits = self.linear_relu_stack(x)\n",
        "    return logits\n",
        "\n",
        "model = NeuralNetwork()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQIse7a-bpGf",
        "outputId": "e716af38-57d4-42ef-d1e9-6a73963d81aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NeuralNetwork(\n",
              "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "  (linear_relu_stack): Sequential(\n",
              "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameters"
      ],
      "metadata": {
        "id": "6kOtbq7XdcWu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "하이퍼파라미터는 모델 최적화 과정에 영향을 주는 설정값. 값에 따라 학습 속도와 성능이 달라지므로 잘 조정해야됨\n",
        "\n",
        "- epoch : 데이터셋을 몇번 반복할지\n",
        "- batch size : 한번에 모델에 넣을 데이터 개수\n",
        "- learning rate : 파라미터를 얼마나 빠르게 업데이트할"
      ],
      "metadata": {
        "id": "37UbHvO4df7J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 1e-3\n",
        "batch_size = 64\n",
        "epochs = 5"
      ],
      "metadata": {
        "id": "4M36wS9gb2dQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optimization loop"
      ],
      "metadata": {
        "id": "00IzSU7yd5vP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델 학습은 두가지 과정을 반복하면서 이루어짐\n",
        "1. train loop (훈련 루프) : 학습 데이터를 사용하여 모델 파라미터를 업데이트\n",
        "2. test loop (검증 루프) : 테스트 데이터를 사용하여 모델 성능을 측정\n",
        "\n"
      ],
      "metadata": {
        "id": "HU65IR3wd9d0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loss Function"
      ],
      "metadata": {
        "id": "7CLEuaE3eN-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "손실 함수는 예측값과 실제 정답의 차이를 계산함\n",
        "\n",
        "분류 문제는 주로 nn.CrossEntropyLoss() 를 주로 사"
      ],
      "metadata": {
        "id": "wvCEn3W3eQik"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "r8T8-sved4sP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optimizer"
      ],
      "metadata": {
        "id": "Kvquw1gieb3C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "손실을 줄이기 위해 모델 파라미터를 업데이트하는 알고리즘"
      ],
      "metadata": {
        "id": "OaZVhMRsefts"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)"
      ],
      "metadata": {
        "id": "kVYoGraDebN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Full Implementation"
      ],
      "metadata": {
        "id": "ouaiDe38fCrE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련 루프\n",
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "  size = len(dataloader.dataset)\n",
        "  model.train()\n",
        "\n",
        "  for batch, (X, y) in enumerate(dataloader):\n",
        "    pred = model(X)\n",
        "    loss = loss_fn(pred, y)\n",
        "\n",
        "    # optimization 하는 3단\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      print(f\"loss: {loss.item():>7} [{batch * batch_size + len(X):>5d}/{size:>5}]\")\n",
        "\n",
        "# 테스트 루프\n",
        "def test_loop(dataloader, model, loss_fn):\n",
        "  model.eval()\n",
        "  size = len(dataloader.dataset)\n",
        "  num_batches = len(dataloader)\n",
        "  test_loss, correct = 0, 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for X, y in dataloader:\n",
        "      pred = model(X)\n",
        "      test_loss += loss_fn(pred, y).item()\n",
        "      correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "  test_loss /= num_batches\n",
        "  correct /= size\n",
        "  print(f\"test error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ],
      "metadata": {
        "id": "wMQhDFbcep2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
        "\n",
        "epochs = 10\n",
        "for t in range(epochs):\n",
        "  print(f\"EPOCH {t+1}\\n---------------------\")\n",
        "  train_loop(train_dataloader, model, loss_fn, optimizer)\n",
        "  test_loop(test_dataloader, model, loss_fn)\n",
        "\n",
        "print(\"끝\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdD3VE0Xgtce",
        "outputId": "3da59395-edd1-4511-e1e0-b4576d7a7566"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH 1\n",
            "---------------------\n",
            "loss: 2.320664882659912 [   64/60000]\n",
            "loss: 2.2948029041290283 [ 6464/60000]\n",
            "loss: 2.28288197517395 [12864/60000]\n",
            "loss: 2.2696921825408936 [19264/60000]\n",
            "loss: 2.252969741821289 [25664/60000]\n",
            "loss: 2.238802433013916 [32064/60000]\n",
            "loss: 2.2357337474823 [38464/60000]\n",
            "loss: 2.2115561962127686 [44864/60000]\n",
            "loss: 2.2148666381835938 [51264/60000]\n",
            "loss: 2.1782004833221436 [57664/60000]\n",
            "test error: \n",
            " Accuracy: 50.7%, Avg loss: 2.173300 \n",
            "\n",
            "EPOCH 2\n",
            "---------------------\n",
            "loss: 2.197521209716797 [   64/60000]\n",
            "loss: 2.171201229095459 [ 6464/60000]\n",
            "loss: 2.1233208179473877 [12864/60000]\n",
            "loss: 2.1329259872436523 [19264/60000]\n",
            "loss: 2.085287570953369 [25664/60000]\n",
            "loss: 2.0416107177734375 [32064/60000]\n",
            "loss: 2.0599353313446045 [38464/60000]\n",
            "loss: 1.9914841651916504 [44864/60000]\n",
            "loss: 1.9989672899246216 [51264/60000]\n",
            "loss: 1.9290918111801147 [57664/60000]\n",
            "test error: \n",
            " Accuracy: 62.3%, Avg loss: 1.923103 \n",
            "\n",
            "EPOCH 3\n",
            "---------------------\n",
            "loss: 1.9623866081237793 [   64/60000]\n",
            "loss: 1.917948603630066 [ 6464/60000]\n",
            "loss: 1.8081132173538208 [12864/60000]\n",
            "loss: 1.8483402729034424 [19264/60000]\n",
            "loss: 1.7355785369873047 [25664/60000]\n",
            "loss: 1.6893137693405151 [32064/60000]\n",
            "loss: 1.7033039331436157 [38464/60000]\n",
            "loss: 1.6051379442214966 [44864/60000]\n",
            "loss: 1.6288384199142456 [51264/60000]\n",
            "loss: 1.524766445159912 [57664/60000]\n",
            "test error: \n",
            " Accuracy: 62.9%, Avg loss: 1.540434 \n",
            "\n",
            "EPOCH 4\n",
            "---------------------\n",
            "loss: 1.610426664352417 [   64/60000]\n",
            "loss: 1.5594239234924316 [ 6464/60000]\n",
            "loss: 1.4147394895553589 [12864/60000]\n",
            "loss: 1.4915465116500854 [19264/60000]\n",
            "loss: 1.3598724603652954 [25664/60000]\n",
            "loss: 1.3587819337844849 [32064/60000]\n",
            "loss: 1.3658236265182495 [38464/60000]\n",
            "loss: 1.2924829721450806 [44864/60000]\n",
            "loss: 1.3307993412017822 [51264/60000]\n",
            "loss: 1.227076768875122 [57664/60000]\n",
            "test error: \n",
            " Accuracy: 63.9%, Avg loss: 1.258096 \n",
            "\n",
            "EPOCH 5\n",
            "---------------------\n",
            "loss: 1.3432364463806152 [   64/60000]\n",
            "loss: 1.3064852952957153 [ 6464/60000]\n",
            "loss: 1.1488606929779053 [12864/60000]\n",
            "loss: 1.2599897384643555 [19264/60000]\n",
            "loss: 1.1255992650985718 [25664/60000]\n",
            "loss: 1.1533668041229248 [32064/60000]\n",
            "loss: 1.1689001321792603 [38464/60000]\n",
            "loss: 1.1075489521026611 [44864/60000]\n",
            "loss: 1.1501507759094238 [51264/60000]\n",
            "loss: 1.0636522769927979 [57664/60000]\n",
            "test error: \n",
            " Accuracy: 64.9%, Avg loss: 1.090071 \n",
            "\n",
            "EPOCH 6\n",
            "---------------------\n",
            "loss: 1.1714166402816772 [   64/60000]\n",
            "loss: 1.1519922018051147 [ 6464/60000]\n",
            "loss: 0.9800550937652588 [12864/60000]\n",
            "loss: 1.1206201314926147 [19264/60000]\n",
            "loss: 0.989267885684967 [25664/60000]\n",
            "loss: 1.0201807022094727 [32064/60000]\n",
            "loss: 1.0525859594345093 [38464/60000]\n",
            "loss: 0.9930920004844666 [44864/60000]\n",
            "loss: 1.034987449645996 [51264/60000]\n",
            "loss: 0.9648014903068542 [57664/60000]\n",
            "test error: \n",
            " Accuracy: 66.2%, Avg loss: 0.984354 \n",
            "\n",
            "EPOCH 7\n",
            "---------------------\n",
            "loss: 1.0540385246276855 [   64/60000]\n",
            "loss: 1.0531141757965088 [ 6464/60000]\n",
            "loss: 0.8660044074058533 [12864/60000]\n",
            "loss: 1.0295510292053223 [19264/60000]\n",
            "loss: 0.9058525562286377 [25664/60000]\n",
            "loss: 0.9268836975097656 [32064/60000]\n",
            "loss: 0.9772788882255554 [38464/60000]\n",
            "loss: 0.9187020063400269 [44864/60000]\n",
            "loss: 0.9555330276489258 [51264/60000]\n",
            "loss: 0.8981660604476929 [57664/60000]\n",
            "test error: \n",
            " Accuracy: 67.3%, Avg loss: 0.912204 \n",
            "\n",
            "EPOCH 8\n",
            "---------------------\n",
            "loss: 0.9672141671180725 [   64/60000]\n",
            "loss: 0.9840897917747498 [ 6464/60000]\n",
            "loss: 0.783758282661438 [12864/60000]\n",
            "loss: 0.9650225639343262 [19264/60000]\n",
            "loss: 0.8497907519340515 [25664/60000]\n",
            "loss: 0.8577263951301575 [32064/60000]\n",
            "loss: 0.92391437292099 [38464/60000]\n",
            "loss: 0.8684089183807373 [44864/60000]\n",
            "loss: 0.8979230523109436 [51264/60000]\n",
            "loss: 0.8490338921546936 [57664/60000]\n",
            "test error: \n",
            " Accuracy: 68.4%, Avg loss: 0.859758 \n",
            "\n",
            "EPOCH 9\n",
            "---------------------\n",
            "loss: 0.8994877934455872 [   64/60000]\n",
            "loss: 0.932049036026001 [ 6464/60000]\n",
            "loss: 0.7219547033309937 [12864/60000]\n",
            "loss: 0.9165592193603516 [19264/60000]\n",
            "loss: 0.8091679215431213 [25664/60000]\n",
            "loss: 0.8051282167434692 [32064/60000]\n",
            "loss: 0.8831682801246643 [38464/60000]\n",
            "loss: 0.8332532644271851 [44864/60000]\n",
            "loss: 0.8546801209449768 [51264/60000]\n",
            "loss: 0.8110264539718628 [57664/60000]\n",
            "test error: \n",
            " Accuracy: 69.7%, Avg loss: 0.819727 \n",
            "\n",
            "EPOCH 10\n",
            "---------------------\n",
            "loss: 0.8449416756629944 [   64/60000]\n",
            "loss: 0.8902168273925781 [ 6464/60000]\n",
            "loss: 0.6736559271812439 [12864/60000]\n",
            "loss: 0.87856125831604 [19264/60000]\n",
            "loss: 0.7777648568153381 [25664/60000]\n",
            "loss: 0.7648017406463623 [32064/60000]\n",
            "loss: 0.8500269055366516 [38464/60000]\n",
            "loss: 0.8072601556777954 [44864/60000]\n",
            "loss: 0.8211017847061157 [51264/60000]\n",
            "loss: 0.7802385091781616 [57664/60000]\n",
            "test error: \n",
            " Accuracy: 70.9%, Avg loss: 0.787813 \n",
            "\n",
            "끝\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SrviyJjWhQk6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}